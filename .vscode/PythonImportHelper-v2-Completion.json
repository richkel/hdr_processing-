[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "exifread",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "exifread",
        "description": "exifread",
        "detail": "exifread",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocationOutput",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "OutputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation_output",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "BaseInvocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InputField",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "InvocationContext",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "invocation",
        "importPath": "invokeai.app.invocations.baseinvocation",
        "description": "invokeai.app.invocations.baseinvocation",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.baseinvocation",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageField",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "ImageCollectionOutput",
        "importPath": "invokeai.app.invocations.primitives",
        "description": "invokeai.app.invocations.primitives",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.primitives",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ResourceOrigin",
        "importPath": "invokeai.app.invocations.image",
        "description": "invokeai.app.invocations.image",
        "isExtraImport": true,
        "detail": "invokeai.app.invocations.image",
        "documentation": {}
    },
    {
        "label": "UnifiedHDRProcessingInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "class UnifiedHDRProcessingInvocation(BaseInvocation):\n    input_images: list[ImageField] = InputField(description=\"Input images for HDR processing\")\n    exposure_times: list[float] = InputField(description=\"Exposure times for each input image\")\n    pseudo_exposure_factors: list[float] = InputField(description=\"Pseudo exposure factors for single image HDR\", default=[])\n    def adjust_brightness(self, image, factor):\n        enhancer = ImageEnhance.Brightness(image)\n        return enhancer.enhance(factor)\n    def create_pseudo_hdr_image(self, base_image, factors):\n        pseudo_hdr_stack = [self.adjust_brightness(base_image, factor) for factor in factors]\n        return [cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR) for image in pseudo_hdr_stack]",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "RetrieveImagesFromFileInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "class RetrieveImagesFromFileInvocation(BaseInvocation):\n    input_path: str = InputField(description=\"Path to the file or directory containing images\")\n    save_to_zip: bool = InputField(description=\"Save all retrieved images to a ZIP file.\", default=False)\n    zip_save_path: str = InputField(description=\"Custom path to save the ZIP file.\", default=\"\")\n    def invoke(self, context: InvocationContext) -> ImageCollectionOutput:\n        try:\n            selected_images = self.get_images_from_path(self.input_path)\n            processed_images = []\n            metadata_collection = []\n            for image_path in selected_images:",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "extract_metadata",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\n# HDR Processing Functions\ndef linearWeight(pixel_value):",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "linearWeight",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def linearWeight(pixel_value):\n    z_min, z_max = 0., 255.\n    return pixel_value - z_min if pixel_value <= (z_min + z_max) / 2 else z_max - pixel_value\ndef sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "sampleIntensities",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):\n        rows, cols = np.where(mid_img == i)\n        if len(rows) != 0:\n            idx = random.randrange(len(rows))",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "computeResponseCurve",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def computeResponseCurve(intensity_samples, log_exposures, smoothing_lambda, weighting_function):\n    z_min, z_max = 0, 255\n    intensity_range = 255\n    num_samples = intensity_samples.shape[0]\n    num_images = len(log_exposures)\n    mat_A = np.zeros((num_images * num_samples + intensity_range, num_samples + intensity_range + 1), dtype=np.float64)\n    mat_b = np.zeros((mat_A.shape[0], 1), dtype=np.float64)\n    k = 0\n    for i in range(num_samples):\n        for j in range(num_images):",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "computeRadianceMap",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def computeRadianceMap(images, log_exposure_times, response_curve, weighting_function):\n    img_shape = images[0].shape\n    img_rad_map = np.zeros(img_shape, dtype=np.float64)\n    num_images = len(images)\n    for i in range(img_shape[0]):\n        for j in range(img_shape[1]):\n            g = np.array([response_curve[images[k][i, j]] for k in range(num_images)])\n            w = np.array([weighting_function(images[k][i, j]) for k in range(num_images)])\n            SumW = np.sum(w)\n            if SumW > 0:",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "globalToneMapping",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def globalToneMapping(image, gamma):\n    image_corrected = cv2.pow(image / 255., 1.0 / gamma)\n    return image_corrected\ndef intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "intensityAdjustment",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output\ndef computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "computeHDR",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "def computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)\n    for channel in range(num_channels):\n        layer_stack = [img[:,:, channel] for img in images]\n        intensity_samples = sampleIntensities(layer_stack)\n        response_curve = computeResponseCurve(intensity_samples, log_exposure_times, smoothing_lambda, linearWeight)\n        img_rad_map = computeRadianceMap(layer_stack, log_exposure_times, response_curve, linearWeight)\n        hdr_image[..., channel] = cv2.normalize(img_rad_map, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n    image_mapped = globalToneMapping(hdr_image, gamma)",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".history.hdr_processing_20231208145547",
        "description": ".history.hdr_processing_20231208145547",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Function to extract metadata\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}",
        "detail": ".history.hdr_processing_20231208145547",
        "documentation": {}
    },
    {
        "label": "UnifiedHDRProcessingInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "class UnifiedHDRProcessingInvocation(BaseInvocation):\n    input_images: list[ImageField] = InputField(description=\"Input images for HDR processing\")\n    exposure_times: list[float] = InputField(description=\"Exposure times for each input image\")\n    pseudo_exposure_factors: list[float] = InputField(description=\"Pseudo exposure factors for single image HDR\", default=[])\n    def adjust_brightness(self, image, factor):\n        enhancer = ImageEnhance.Brightness(image)\n        return enhancer.enhance(factor)\n    def create_pseudo_hdr_image(self, base_image, factors):\n        pseudo_hdr_stack = [self.adjust_brightness(base_image, factor) for factor in factors]\n        return [cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR) for image in pseudo_hdr_stack]",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "RetrieveImagesFromFileInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "class RetrieveImagesFromFileInvocation(BaseInvocation):\n    input_path: str = InputField(description=\"Path to the file or directory containing images\")\n    save_to_zip: bool = InputField(description=\"Save all retrieved images to a ZIP file.\", default=False)\n    zip_save_path: str = InputField(description=\"Custom path to save the ZIP file.\", default=\"\")\n    def invoke(self, context: InvocationContext) -> ImageCollectionOutput:\n        try:\n            selected_images = self.get_images_from_path(self.input_path)\n            processed_images = []\n            metadata_collection = []\n            for image_path in selected_images:",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "extract_metadata",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\n# HDR Processing Functions\ndef linearWeight(pixel_value):",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "linearWeight",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def linearWeight(pixel_value):\n    z_min, z_max = 0., 255.\n    return pixel_value - z_min if pixel_value <= (z_min + z_max) / 2 else z_max - pixel_value\ndef sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "sampleIntensities",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):\n        rows, cols = np.where(mid_img == i)\n        if len(rows) != 0:\n            idx = random.randrange(len(rows))",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "computeResponseCurve",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def computeResponseCurve(intensity_samples, log_exposures, smoothing_lambda, weighting_function):\n    z_min, z_max = 0, 255\n    intensity_range = 255\n    num_samples = intensity_samples.shape[0]\n    num_images = len(log_exposures)\n    mat_A = np.zeros((num_images * num_samples + intensity_range, num_samples + intensity_range + 1), dtype=np.float64)\n    mat_b = np.zeros((mat_A.shape[0], 1), dtype=np.float64)\n    k = 0\n    for i in range(num_samples):\n        for j in range(num_images):",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "computeRadianceMap",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def computeRadianceMap(images, log_exposure_times, response_curve, weighting_function):\n    img_shape = images[0].shape\n    img_rad_map = np.zeros(img_shape, dtype=np.float64)\n    num_images = len(images)\n    for i in range(img_shape[0]):\n        for j in range(img_shape[1]):\n            g = np.array([response_curve[images[k][i, j]] for k in range(num_images)])\n            w = np.array([weighting_function(images[k][i, j]) for k in range(num_images)])\n            SumW = np.sum(w)\n            if SumW > 0:",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "globalToneMapping",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def globalToneMapping(image, gamma):\n    image_corrected = cv2.pow(image / 255., 1.0 / gamma)\n    return image_corrected\ndef intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "intensityAdjustment",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output\ndef computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "computeHDR",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "def computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)\n    for channel in range(num_channels):\n        layer_stack = [img[:,:, channel] for img in images]\n        intensity_samples = sampleIntensities(layer_stack)\n        response_curve = computeResponseCurve(intensity_samples, log_exposure_times, smoothing_lambda, linearWeight)\n        img_rad_map = computeRadianceMap(layer_stack, log_exposure_times, response_curve, linearWeight)\n        hdr_image[..., channel] = cv2.normalize(img_rad_map, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n    image_mapped = globalToneMapping(hdr_image, gamma)",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".history.hdr_processing_20231208171238",
        "description": ".history.hdr_processing_20231208171238",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Function to extract metadata\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}",
        "detail": ".history.hdr_processing_20231208171238",
        "documentation": {}
    },
    {
        "label": "UnifiedHDRProcessingInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "class UnifiedHDRProcessingInvocation(BaseInvocation):\n    input_images: list[ImageField] = InputField(description=\"Input images for HDR processing\")\n    exposure_times: list[float] = InputField(description=\"Exposure times for each input image\")\n    pseudo_exposure_factors: list[float] = InputField(description=\"Pseudo exposure factors for single image HDR\", default=[])\n    def adjust_brightness(self, image, factor):\n        enhancer = ImageEnhance.Brightness(image)\n        return enhancer.enhance(factor)\n    def create_pseudo_hdr_image(self, base_image, factors):\n        pseudo_hdr_stack = [self.adjust_brightness(base_image, factor) for factor in factors]\n        return [cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR) for image in pseudo_hdr_stack]",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "RetrieveImagesFromFileInvocation",
        "kind": 6,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "class RetrieveImagesFromFileInvocation(BaseInvocation):\n    input_path: str = InputField(description=\"Path to the file or directory containing images\")\n    save_to_zip: bool = InputField(description=\"Save all retrieved images to a ZIP file.\", default=False)\n    zip_save_path: str = InputField(description=\"Custom path to save the ZIP file.\", default=\"\")\n    def invoke(self, context: InvocationContext) -> ImageCollectionOutput:\n        try:\n            selected_images = self.get_images_from_path(self.input_path)\n            processed_images = []\n            metadata_collection = []\n            for image_path in selected_images:",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "extract_metadata",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\n# HDR Processing Functions\ndef linearWeight(pixel_value):",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "linearWeight",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def linearWeight(pixel_value):\n    z_min, z_max = 0., 255.\n    return pixel_value - z_min if pixel_value <= (z_min + z_max) / 2 else z_max - pixel_value\ndef sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "sampleIntensities",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):\n        rows, cols = np.where(mid_img == i)\n        if len(rows) != 0:\n            idx = random.randrange(len(rows))",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "computeResponseCurve",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def computeResponseCurve(intensity_samples, log_exposures, smoothing_lambda, weighting_function):\n    z_min, z_max = 0, 255\n    intensity_range = 255\n    num_samples = intensity_samples.shape[0]\n    num_images = len(log_exposures)\n    mat_A = np.zeros((num_images * num_samples + intensity_range, num_samples + intensity_range + 1), dtype=np.float64)\n    mat_b = np.zeros((mat_A.shape[0], 1), dtype=np.float64)\n    k = 0\n    for i in range(num_samples):\n        for j in range(num_images):",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "computeRadianceMap",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def computeRadianceMap(images, log_exposure_times, response_curve, weighting_function):\n    img_shape = images[0].shape\n    img_rad_map = np.zeros(img_shape, dtype=np.float64)\n    num_images = len(images)\n    for i in range(img_shape[0]):\n        for j in range(img_shape[1]):\n            g = np.array([response_curve[images[k][i, j]] for k in range(num_images)])\n            w = np.array([weighting_function(images[k][i, j]) for k in range(num_images)])\n            SumW = np.sum(w)\n            if SumW > 0:",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "globalToneMapping",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def globalToneMapping(image, gamma):\n    image_corrected = cv2.pow(image / 255., 1.0 / gamma)\n    return image_corrected\ndef intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "intensityAdjustment",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output\ndef computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "computeHDR",
        "kind": 2,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "def computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)\n    for channel in range(num_channels):\n        layer_stack = [img[:,:, channel] for img in images]\n        intensity_samples = sampleIntensities(layer_stack)\n        response_curve = computeResponseCurve(intensity_samples, log_exposure_times, smoothing_lambda, linearWeight)\n        img_rad_map = computeRadianceMap(layer_stack, log_exposure_times, response_curve, linearWeight)\n        hdr_image[..., channel] = cv2.normalize(img_rad_map, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n    image_mapped = globalToneMapping(hdr_image, gamma)",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": ".history.hdr_processing_20231208171420",
        "description": ".history.hdr_processing_20231208171420",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Function to extract metadata\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}",
        "detail": ".history.hdr_processing_20231208171420",
        "documentation": {}
    },
    {
        "label": "SimulatedExposureTimes",
        "kind": 6,
        "importPath": "exposuretimesnode",
        "description": "exposuretimesnode",
        "peekOfCode": "class SimulatedExposureTimes(Enum):\n    LONG_EXPOSURE = (30, \"Specialty night and low-light photos on a tripod\")\n    SILKY_WATER = (0.5, \"Silky look to flowing water, landscape photos on tripod\")\n    MOTION_BLUR = (1/15, \"Motion blur in background, hand-held photos with stabilization\")\n    HAND_HELD = (1/60, \"Typical hand-held photos without substantial zoom\")\n    ACTION_FREEZE = (1/250, \"Freeze everyday sports/action subject movement, telephoto lens\")\n    FAST_ACTION = (1/2000, \"Freeze extremely fast, up-close subject motion\")\n@invocation_output('exposure_times_output')\nclass ExposureTimesOutput(BaseInvocationOutput):\n    exposure_times: list[float] = OutputField(description=\"Exposure times for HDR image processing.\")",
        "detail": "exposuretimesnode",
        "documentation": {}
    },
    {
        "label": "ExposureTimesOutput",
        "kind": 6,
        "importPath": "exposuretimesnode",
        "description": "exposuretimesnode",
        "peekOfCode": "class ExposureTimesOutput(BaseInvocationOutput):\n    exposure_times: list[float] = OutputField(description=\"Exposure times for HDR image processing.\")\n    @validator('exposure_times', each_item=True)\n    def check_positive(cls, v):\n        if v <= 0:\n            raise ValueError(\"Exposure times must be positive numbers.\")\n        return v\n@invocation(\"exposure_times\", title=\"Exposure Times for HDR\", tags=[\"hdr\", \"exposure\"], category=\"image\", version=\"0.1.0\", use_cache=False)\nclass ExposureTimesInvocation(BaseInvocation):\n    use_simulated_exposures: bool = InputField(description=\"Use simulated exposure times for HDR images.\", default=False)",
        "detail": "exposuretimesnode",
        "documentation": {}
    },
    {
        "label": "ExposureTimesInvocation",
        "kind": 6,
        "importPath": "exposuretimesnode",
        "description": "exposuretimesnode",
        "peekOfCode": "class ExposureTimesInvocation(BaseInvocation):\n    use_simulated_exposures: bool = InputField(description=\"Use simulated exposure times for HDR images.\", default=False)\n    user_exposure_times: list[float] = InputField(description=\"Custom exposure times provided by the user.\", default=[])\n    image_metadata: list[dict] = InputField(description=\"Metadata for each image\", default=[])\n    default_exposure_time: float = InputField(description=\"Default exposure time if not found in metadata\", default=1/60)\n    def calculate_exposure_time(self, metadata):\n        # List of possible keys for exposure time in metadata\n        possible_keys = ['EXIF ExposureTime', 'ExposureTime', 'Exposure Time']\n        for key in possible_keys:\n            exposure_time = metadata.get(key)",
        "detail": "exposuretimesnode",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "exposuretimesnode",
        "description": "exposuretimesnode",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Updated Enum for simulated exposure times with descriptions\nclass SimulatedExposureTimes(Enum):\n    LONG_EXPOSURE = (30, \"Specialty night and low-light photos on a tripod\")\n    SILKY_WATER = (0.5, \"Silky look to flowing water, landscape photos on tripod\")\n    MOTION_BLUR = (1/15, \"Motion blur in background, hand-held photos with stabilization\")\n    HAND_HELD = (1/60, \"Typical hand-held photos without substantial zoom\")\n    ACTION_FREEZE = (1/250, \"Freeze everyday sports/action subject movement, telephoto lens\")\n    FAST_ACTION = (1/2000, \"Freeze extremely fast, up-close subject motion\")\n@invocation_output('exposure_times_output')",
        "detail": "exposuretimesnode",
        "documentation": {}
    },
    {
        "label": "UnifiedHDRProcessingInvocation",
        "kind": 6,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "class UnifiedHDRProcessingInvocation(BaseInvocation):\n    input_images: list[ImageField] = InputField(description=\"Input images for HDR processing\")\n    exposure_times: list[float] = InputField(description=\"Exposure times for each input image\")\n    pseudo_exposure_factors: list[float] = InputField(description=\"Pseudo exposure factors for single image HDR\", default=[])\n    def adjust_brightness(self, image, factor):\n        enhancer = ImageEnhance.Brightness(image)\n        return enhancer.enhance(factor)\n    def create_pseudo_hdr_image(self, base_image, factors):\n        pseudo_hdr_stack = [self.adjust_brightness(base_image, factor) for factor in factors]\n        return [cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR) for image in pseudo_hdr_stack]",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "RetrieveImagesFromFileInvocation",
        "kind": 6,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "class RetrieveImagesFromFileInvocation(BaseInvocation):\n    input_path: str = InputField(description=\"Path to the file or directory containing images\")\n    save_to_zip: bool = InputField(description=\"Save all retrieved images to a ZIP file.\", default=False)\n    zip_save_path: str = InputField(description=\"Custom path to save the ZIP file.\", default=\"\")\n    def invoke(self, context: InvocationContext) -> ImageCollectionOutput:\n        try:\n            selected_images = self.get_images_from_path(self.input_path)\n            processed_images = []\n            metadata_collection = []\n            for image_path in selected_images:",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "extract_metadata",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\n# HDR Processing Functions\ndef linearWeight(pixel_value):",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "linearWeight",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def linearWeight(pixel_value):\n    z_min, z_max = 0., 255.\n    return pixel_value - z_min if pixel_value <= (z_min + z_max) / 2 else z_max - pixel_value\ndef sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "sampleIntensities",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def sampleIntensities(images):\n    z_min, z_max = 0, 255\n    num_intensities = z_max - z_min + 1\n    num_images = len(images)\n    intensity_values = np.zeros((num_intensities, num_images), dtype=np.uint8)\n    mid_img = images[num_images // 2]\n    for i in range(z_min, z_max + 1):\n        rows, cols = np.where(mid_img == i)\n        if len(rows) != 0:\n            idx = random.randrange(len(rows))",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "computeResponseCurve",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def computeResponseCurve(intensity_samples, log_exposures, smoothing_lambda, weighting_function):\n    z_min, z_max = 0, 255\n    intensity_range = 255\n    num_samples = intensity_samples.shape[0]\n    num_images = len(log_exposures)\n    mat_A = np.zeros((num_images * num_samples + intensity_range, num_samples + intensity_range + 1), dtype=np.float64)\n    mat_b = np.zeros((mat_A.shape[0], 1), dtype=np.float64)\n    k = 0\n    for i in range(num_samples):\n        for j in range(num_images):",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "computeRadianceMap",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def computeRadianceMap(images, log_exposure_times, response_curve, weighting_function):\n    img_shape = images[0].shape\n    img_rad_map = np.zeros(img_shape, dtype=np.float64)\n    num_images = len(images)\n    for i in range(img_shape[0]):\n        for j in range(img_shape[1]):\n            g = np.array([response_curve[images[k][i, j]] for k in range(num_images)])\n            w = np.array([weighting_function(images[k][i, j]) for k in range(num_images)])\n            SumW = np.sum(w)\n            if SumW > 0:",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "globalToneMapping",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def globalToneMapping(image, gamma):\n    image_corrected = cv2.pow(image / 255., 1.0 / gamma)\n    return image_corrected\ndef intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "intensityAdjustment",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def intensityAdjustment(image, template):\n    m, n, channel = image.shape\n    output = np.zeros((m, n, channel))\n    for ch in range(channel):\n        image_avg, template_avg = np.average(image[:,:, ch]), np.average(template[:,:, ch])\n        output[..., ch] = image[..., ch] * (template_avg / image_avg)\n    return output\ndef computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "computeHDR",
        "kind": 2,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "def computeHDR(images, log_exposure_times, smoothing_lambda=100., gamma=0.6):\n    num_channels = images[0].shape[2]\n    hdr_image = np.zeros(images[0].shape, dtype=np.float64)\n    for channel in range(num_channels):\n        layer_stack = [img[:,:, channel] for img in images]\n        intensity_samples = sampleIntensities(layer_stack)\n        response_curve = computeResponseCurve(intensity_samples, log_exposure_times, smoothing_lambda, linearWeight)\n        img_rad_map = computeRadianceMap(layer_stack, log_exposure_times, response_curve, linearWeight)\n        hdr_image[..., channel] = cv2.normalize(img_rad_map, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n    image_mapped = globalToneMapping(hdr_image, gamma)",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "hdr_processing",
        "description": "hdr_processing",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Function to extract metadata\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}",
        "detail": "hdr_processing",
        "documentation": {}
    },
    {
        "label": "ImageZipResult",
        "kind": 6,
        "importPath": "retrieveimagesfromfile",
        "description": "retrieveimagesfromfile",
        "peekOfCode": "class ImageZipResult(BaseModel):\n    message: str\n@invocation(\n    \"Retrieve_Images_From_File\",\n    title=\"Retrieve Images from File or Directory\",\n    tags=[\"image\", \"file\"],\n    category=\"image\",\n    version=\"0.1.0\",\n    use_cache=False\n)",
        "detail": "retrieveimagesfromfile",
        "documentation": {}
    },
    {
        "label": "RetrieveImagesFromFileInvocation",
        "kind": 6,
        "importPath": "retrieveimagesfromfile",
        "description": "retrieveimagesfromfile",
        "peekOfCode": "class RetrieveImagesFromFileInvocation(BaseInvocation):\n    input_path: str = InputField(description=\"Path to the file or directory containing images\")\n    save_to_zip: bool = InputField(description=\"Save all retrieved images to a ZIP file.\", default=False)\n    zip_save_path: str = InputField(description=\"Custom path to save the ZIP file.\", default=\"\")\n    def invoke(self, context: InvocationContext) -> ImageCollectionOutput:\n        try:\n            selected_images = self.get_images_from_path(self.input_path)\n            processed_images = []\n            metadata_collection = []\n            for image_path in selected_images:",
        "detail": "retrieveimagesfromfile",
        "documentation": {}
    },
    {
        "label": "extract_metadata",
        "kind": 2,
        "importPath": "retrieveimagesfromfile",
        "description": "retrieveimagesfromfile",
        "peekOfCode": "def extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\nclass ImageZipResult(BaseModel):\n    message: str",
        "detail": "retrieveimagesfromfile",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "retrieveimagesfromfile",
        "description": "retrieveimagesfromfile",
        "peekOfCode": "logger = logging.getLogger(__name__)\nSCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}",
        "detail": "retrieveimagesfromfile",
        "documentation": {}
    },
    {
        "label": "SCRIPT_DIR",
        "kind": 5,
        "importPath": "retrieveimagesfromfile",
        "description": "retrieveimagesfromfile",
        "peekOfCode": "SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\ndef extract_metadata(image_path):\n    try:\n        with open(image_path, 'rb') as img_file:\n            tags = exifread.process_file(img_file)\n            return {tag: str(tags[tag]) for tag in tags if tag not in ['JPEGThumbnail', 'TIFFThumbnail', 'Filename', 'EXIF MakerNote']}\n    except Exception as e:\n        logger.error(f\"Error extracting metadata from {image_path}: {e}\", exc_info=True)\n        return {}\nclass ImageZipResult(BaseModel):",
        "detail": "retrieveimagesfromfile",
        "documentation": {}
    },
    {
        "label": "UserInputinvocation",
        "kind": 6,
        "importPath": "UserInputNode",
        "description": "UserInputNode",
        "peekOfCode": "class UserInputinvocation(BaseInvocation):\n    \"\"\"\n    Custom node for user input in HDR image processing. This node allows users to input a custom exposure time.\n    \"\"\"\n    custom_exposure_time: float = InputField(description=\"Custom exposure time entered by the user.\", default=1/60)\n    def invoke(self, context: InvocationContext) -> dict:\n        \"\"\"\n        Invokes the User Input Node and validates the user's input.\n        Args:\n            context (InvocationContext): The context in which the node is invoked.",
        "detail": "UserInputNode",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "UserInputNode",
        "description": "UserInputNode",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@invocation(\"User_Input_Node\", title=\"User Input for HDR\", tags=[\"hdr\", \"input\"], category=\"input\", version=\"1.0.0\", use_cache=False)\nclass UserInputinvocation(BaseInvocation):\n    \"\"\"\n    Custom node for user input in HDR image processing. This node allows users to input a custom exposure time.\n    \"\"\"\n    custom_exposure_time: float = InputField(description=\"Custom exposure time entered by the user.\", default=1/60)\n    def invoke(self, context: InvocationContext) -> dict:\n        \"\"\"\n        Invokes the User Input Node and validates the user's input.",
        "detail": "UserInputNode",
        "documentation": {}
    }
]